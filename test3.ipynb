{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af866e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from joblib import dump, load\n",
    "from utils.utils import sliding_window\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fda5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data = pd.read_csv(\"data/extra_info.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac32879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "air = pd.read_csv(\"data/air_data.csv\")\n",
    "weather = pd.read_csv(\"data/weather_data.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d3de33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_np = []\n",
    "air_np = []\n",
    "\n",
    "# take some minutes to run\n",
    "for city_id in ['Hà Nội', 'Hưng Yên', 'Bắc Ninh']:          \n",
    "    # load air quality and weather data files \n",
    "    air_df = air.loc[air['province'] == city_id].drop(columns=['province'])\n",
    "    weather_df = weather.loc[weather['province'] == city_id].drop(columns=['province'])   \n",
    "    \n",
    "    # air quality data preprocessing\n",
    "    air_df = air_df.loc[(air_df.iloc[:, 1:] >= 0).all(axis=1)]\n",
    "    air_df.drop(\"aqi\", axis=1, inplace=True)\n",
    "    air_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # weather data preprocessing\n",
    "    weather_df.dropna(axis=0, inplace=True)\n",
    "    weather_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # making sliding windows\n",
    "    X, y = sliding_window(weather_df, air_df, target_size=\"same\")\n",
    "    \n",
    "    # flatten the windows and concanate extra attibutes\n",
    "    m = X.shape[0]\n",
    "    X = X.reshape((m, -1))\n",
    "    \n",
    "    # add to main dataset arrays\n",
    "    weather_np.append(X)\n",
    "    air_np.append(y)\n",
    "    \n",
    "weather_np = np.vstack(weather_np)\n",
    "air_np = np.vstack(air_np)\n",
    "air_np = air_np[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c788aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_np = weather_np.astype(\"float32\")\n",
    "air_np = air_np.astype(\"float32\")\n",
    "\n",
    "random.seed(42)\n",
    "idx = list(range(len(weather_np)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "train_ratio = 0.8  # 80% train, 20% test\n",
    "split_point = int(train_ratio * len(X))\n",
    "\n",
    "train_idx = idx[:split_point]\n",
    "test_idx = idx[split_point:]\n",
    "X_train, X_test, y_train, y_test = weather_np[train_idx], weather_np[test_idx], air_np[train_idx], air_np[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29f23ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.74250e+02, 1.64500e+01, 6.79500e+01, 1.55000e+01, 1.05120e+02,\n",
       "        1.30650e+02],\n",
       "       [1.05476e+03, 5.07200e+01, 1.16200e+01, 3.57600e+01, 5.45900e+01,\n",
       "        8.11300e+01],\n",
       "       [6.40870e+02, 1.55900e+01, 9.15500e+01, 1.66900e+01, 7.83500e+01,\n",
       "        8.92200e+01],\n",
       "       ...,\n",
       "       [1.60217e+03, 4.52400e+01, 1.07000e+00, 1.43100e+01, 8.21300e+01,\n",
       "        1.06140e+02],\n",
       "       [1.32179e+03, 5.34700e+01, 3.29000e+01, 3.43300e+01, 1.14360e+02,\n",
       "        1.18500e+02],\n",
       "       [8.67840e+02, 2.14200e+01, 1.05860e+02, 1.74000e+01, 5.77400e+01,\n",
       "        6.92600e+01]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5efc928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.4,  64. ,   7.6, ..., 100. ,  10.5,  22. ],\n",
       "       [ 22.6,  93. ,  21.4, ...,  35. ,   4. ,  95. ],\n",
       "       [ 13.5,  88. ,  11.6, ...,  12. ,   1.1,  18. ],\n",
       "       ...,\n",
       "       [ 25.7,  91. ,  24.2, ...,  98. ,   3.8, 319. ],\n",
       "       [ 27.1,  94. ,  26.1, ...,  99. ,   2.2,  81. ],\n",
       "       [ 26.5,  92. ,  25.1, ...,  74. ,   3.9, 202. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3495282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hungn\\miniconda3\\Lib\\site-packages\\sklearn\\compose\\_target.py:210: UserWarning: The provided functions or transformer are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom RMSE score: -0.539310617595306\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('forest', RandomForestRegressor(n_estimators=30, max_depth=60, min_samples_split=2, min_samples_leaf=2, n_jobs=-1))    \n",
    "])\n",
    "\n",
    "model = TransformedTargetRegressor(\n",
    "    regressor=pipeline,\n",
    "    transformer=StandardScaler()\n",
    ")\n",
    "\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_y_true = scaler.fit_transform(y_true)\n",
    "    return -root_mean_squared_error(\n",
    "        scaled_y_true,\n",
    "        scaler.transform(y_pred),\n",
    "        multioutput=\"uniform_average\"\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = custom_scorer(y_test.reshape(-1, 1), y_pred.reshape(-1, 1))\n",
    "print(\"Custom RMSE score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118a8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "co       1087.405532\n",
       "no2        16.536725\n",
       "o3         25.473569\n",
       "so2        14.957574\n",
       "pm2_5      62.968041\n",
       "pm10       69.606491\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(root_mean_squared_error(model.predict(X_test), y_test, multioutput=\"raw_values\"), \n",
    "          index=[\"co\", \"no2\", \"o3\", \"so2\", \"pm2_5\", \"pm10\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
